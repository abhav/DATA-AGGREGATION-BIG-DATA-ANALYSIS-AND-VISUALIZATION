{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "fileZipname = '/Users/abhavluthra/Desktop/DIC/Lab2/CC/data.gz'\n",
    "filename = '/Users/abhavluthra/Desktop/DIC/Lab2/CC/data.txt'\n",
    "filewetname = '/Users/abhavluthra/Desktop/DIC/Lab2/CC/wet.paths/wet.paths'\n",
    "baseUrl = 'https://commoncrawl.s3.amazonaws.com/'\n",
    "fileAbhav = '/Users/abhavluthra/Desktop/DIC/Lab2/CC/'\n",
    "querylstAbhav = ['mexico border', 'immigrant', 'border wall', 'build wall']\n",
    "\n",
    "def extract_zip_file():\n",
    "    with gzip.open(fileZipname, 'rb') as f_in:\n",
    "        with open(filename, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)    \n",
    "\n",
    "def load_file(file):\n",
    "    with open(file,  encoding=\"utf8\") as f:\n",
    "        return f.readlines()\n",
    "\n",
    "def download_file_as_gz(url_part):\n",
    "    url = baseUrl + url_part\n",
    "    urllib.request.urlretrieve(url,fileZipname)\n",
    "\n",
    "def removeFile():\n",
    "    os.remove(filename)\n",
    "    os.remove(fileZipname)\n",
    "\n",
    "def process_file():\n",
    "    content = load_file(filename)    \n",
    "    last_i = len(content)\n",
    "    containers = []\n",
    "    for i in range(len(content)):\n",
    "        if content[i].startswith('Content-Length'):\n",
    "            article = ''\n",
    "            i = i+1\n",
    "            while((not (content[i].startswith('WARC'))) and i < (last_i -1)):\n",
    "                article = article + content[i]\n",
    "                i = i + 1\n",
    "            containers.append(article.replace(\"\\n\",\" \").replace(\"\\t\",\" \"))\n",
    "    extract_articles(containers)\n",
    "    \n",
    "def write_to_file(filetowrite, dictData):\n",
    "    for key in dictData:\n",
    "        f=open(filetowrite+key+\".txt\", \"a+\", encoding=\"utf-8\")\n",
    "        for txt in dictData[key]:\n",
    "            f.write(txt+\"\\n\\n\")    \n",
    "        f.close()   \n",
    "    \n",
    "\n",
    "def extract_articles(containers):\n",
    "    final = create_dict(querylstAbhav)\n",
    "    for article in containers:\n",
    "        c = 0\n",
    "        for q in querylstAbhav:\n",
    "            if q in article:\n",
    "                final[q].append(article)\n",
    "    \n",
    "    write_to_file(fileAhbav,final)\n",
    "    final = create_dict(querylstSaurabh)\n",
    "    for article in containers:\n",
    "        c = 0\n",
    "        for q in querylstSaurabh:\n",
    "            if q in article:\n",
    "                final[q].append(article)\n",
    "    \n",
    "    write_to_file(fileSaurabh,final)\n",
    "\n",
    "def create_dict(query):\n",
    "    final = dict.fromkeys(query)\n",
    "    for key in final:\n",
    "        final[key] = []\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wet file which contains link\n",
    "content = load_file(filewetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in content[80:150]:\n",
    "    download_file_as_gz(url)\n",
    "    extract_zip_file()\n",
    "    process_file()\n",
    "    removeFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDataCollector_CC (2).ipynb\u001b[m\u001b[m* \u001b[31mbuild wall.txt\u001b[m\u001b[m*\r\n",
      "\u001b[31mDataCollector_CC.ipynb\u001b[m\u001b[m*     \u001b[31mimmigrant.txt\u001b[m\u001b[m*\r\n",
      "\u001b[31mborder wall.txt\u001b[m\u001b[m*            \u001b[31mmexico border.txt\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize For Co-occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('/Users/abhavluthra/Desktop/DIC/Lab2/CC/border wall.txt', \"r\", encoding='utf-8') as f:\n",
    "    articles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2514"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullarticle = []\n",
    "for article in articles:\n",
    "    lines = nltk.sent_tokenize(article)\n",
    "    for line in lines:\n",
    "        fullarticle.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111589"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullarticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/abhavluthra/Desktop/DIC/Lab2/CC/BorderWall.txt', 'w') as f:\n",
    "    for item in fullarticle:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('/Users/abhavluthra/Desktop/DIC/Lab2/CC/build wall.txt', \"r\", encoding='utf-8') as f:\n",
    "    articles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullarticle = []\n",
    "for article in articles:\n",
    "    lines = nltk.sent_tokenize(article)\n",
    "    for line in lines:\n",
    "        fullarticle.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15900"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullarticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/abhavluthra/Desktop/DIC/Lab2/CC/BuildWall.txt', 'w') as f:\n",
    "    for item in fullarticle:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('/Users/abhavluthra/Desktop/DIC/Lab2/CC/immigrant.txt', \"r\", encoding='utf-8') as f:\n",
    "    articles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728314"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullarticle = []\n",
    "for article in articles:\n",
    "    lines = nltk.sent_tokenize(article)\n",
    "    for line in lines:\n",
    "        fullarticle.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728314"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullarticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/abhavluthra/Desktop/DIC/Lab2/CC/Immigrants.txt', 'w') as f:\n",
    "    for item in fullarticle:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('/Users/abhavluthra/Desktop/DIC/Lab2/CC/mexico border.txt', \"r\", encoding='utf-8') as f:\n",
    "    articles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullarticle = []\n",
    "for article in articles:\n",
    "    lines = nltk.sent_tokenize(article)\n",
    "    for line in lines:\n",
    "        fullarticle.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fullarticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/abhavluthra/Desktop/DIC/Lab2/CC/MexicoBorder.txt', 'w') as f:\n",
    "    for item in fullarticle:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
